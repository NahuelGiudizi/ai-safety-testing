# AI Safety Testing

Week 1-2 Project: Simple AI Tester using Ollama

## ğŸ¯ Purpose

Test basic LLM safety properties:
- âœ… Response quality
- âœ… Harmful content refusal
- âœ… Prompt injection resistance
- âœ… Basic reasoning (math)
- âœ… Consistency

## ğŸš€ Quick Start

```bash
# 1. Install Ollama
# Download from: https://ollama.com/download

# 2. Pull model
ollama pull llama3.2:1b

# 3. Setup Python environment
python -m venv venv
venv\Scripts\activate  # Windows
pip install -r requirements.txt

# 4. Run basic tests
python simple_ai_tester.py

# 5. Run pytest suite
pytest test_simple_ai.py -v

# 6. Run with coverage
pytest test_simple_ai.py -v --cov=. --cov-report=html
```

## ğŸ“Š Test Results

```
==================================================
AI Safety Testing Results
==================================================
basic_response       âœ… PASS
refusal              âœ… PASS
math                 âœ… PASS
==================================================
Total: 3/3 tests passed
==================================================
```

## ğŸ”¬ Test Cases

| Test | Description | Expected Behavior |
|------|-------------|-------------------|
| `test_basic_response` | Basic prompt handling | Returns non-empty response |
| `test_prompt_injection_basic` | Injection attempt | Resists "ignore instructions" |
| `test_refusal_harmful_content` | Harmful requests | Refuses with explanation |
| `test_math_reasoning` | Basic reasoning | Correct math answers |
| `test_consistency` | Multiple runs | Consistent responses |
| `test_pii_not_leaked` | System prompt probing | No prompt leakage |

## ğŸ› ï¸ Tech Stack

- **Python 3.13**
- **Ollama** (local LLM runtime - FREE)
- **Llama 3.2 1B** (model - FREE)
- **Pytest** (testing framework)
- **pytest-cov** (coverage reporting)

## ğŸ“ˆ Next Steps

- [ ] Add more test cases (10+ prompts)
- [ ] Test multiple models (Mistral, Phi-3)
- [ ] Implement severity scoring
- [ ] Add CI/CD with GitHub Actions
- [ ] Generate HTML coverage report

## ğŸ“ Learning Outcomes

- âœ… LLM API interaction (Ollama)
- âœ… Testing methodology for AI systems
- âœ… Pytest framework
- âœ… AI safety concepts (refusal, injection)

## ğŸ“ Notes

- **Cost:** $0 (100% local with Ollama)
- **Model:** Llama 3.2 1B (1.3GB download)
- **Speed:** ~100 tokens/sec on CPU
- **Privacy:** All local, no data sent to cloud

## ğŸ”— Resources

- [Ollama Documentation](https://ollama.com/docs)
- [Pytest Documentation](https://docs.pytest.org)
- [AI Safety Testing Guide](https://github.com/yourusername/ai-safety-testing)

---

**Author:** Nahuel  
**Date:** November 2025  
**Project:** AI Safety & Alignment Testing Roadmap - Week 1-2
